<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Autonomy Expert</title>
    <link rel="preconnect" href="https://fonts.googleapis.com" />
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600&display=swap" rel="stylesheet" />

    <style>
      * {
        margin: 0;
        padding: 0;
        box-sizing: border-box;
      }

      :root {
        --bg-primary: #0a0a0a;
        --bg-secondary: #141414;
        --bg-tertiary: #1a1a1a;
        --border-color: rgba(255, 255, 255, 0.1);
        --text-primary: #ffffff;
        --text-secondary: #a1a1a1;
        --text-muted: #6b6b6b;
        --accent: #e85c2b;
        --accent-hover: #ff6b3d;
        --accent-muted: rgba(232, 92, 43, 0.15);
        --success: #22c55e;
        --error: #ef4444;
      }

      body {
        font-family:
          "Inter",
          -apple-system,
          BlinkMacSystemFont,
          "Segoe UI",
          Roboto,
          sans-serif;
        background: var(--bg-primary);
        height: 100vh;
        display: flex;
        flex-direction: column;
        color: var(--text-primary);
        overflow: hidden;
      }

      /* Header */
      .header {
        display: flex;
        align-items: center;
        justify-content: space-between;
        padding: 16px 32px;
        border-bottom: 1px solid var(--border-color);
        background: var(--bg-primary);
      }

      .logo {
        height: 24px;
        color: var(--text-primary);
      }

      .header-right {
        display: flex;
        align-items: center;
        gap: 24px;
      }

      .header-link {
        color: var(--text-secondary);
        text-decoration: none;
        font-size: 14px;
        font-weight: 500;
        transition: color 0.2s ease;
      }

      .header-link:hover {
        color: var(--text-primary);
      }

      .header-link.accent {
        color: var(--accent);
      }

      .header-link.accent:hover {
        color: var(--accent-hover);
      }

      /* Main container */
      .container {
        display: flex;
        flex-direction: row;
        flex: 1;
        overflow: hidden;
      }

      /* Transcript panel */
      .transcript-panel {
        width: 65%;
        display: flex;
        flex-direction: column;
        padding: 32px;
        background: var(--bg-primary);
        border-right: 1px solid var(--border-color);
        overflow: hidden;
        min-height: 0;
      }

      .transcript-header {
        margin-bottom: 24px;
      }

      .transcript-header h2 {
        font-size: 14px;
        font-weight: 600;
        color: var(--text-muted);
        text-transform: uppercase;
        letter-spacing: 0.5px;
      }

      .transcript-container {
        flex: 1;
        overflow-y: auto;
        background: var(--bg-secondary);
        border: 1px solid var(--border-color);
        border-radius: 12px;
        padding: 24px;
        min-height: 0;
      }

      .transcript-container::-webkit-scrollbar {
        width: 6px;
      }

      .transcript-container::-webkit-scrollbar-track {
        background: transparent;
      }

      .transcript-container::-webkit-scrollbar-thumb {
        background: var(--border-color);
        border-radius: 3px;
      }

      .transcript-item {
        margin-bottom: 16px;
        padding: 16px;
        border-radius: 8px;
        font-size: 14px;
        line-height: 1.7;
      }

      .transcript-item.user {
        background: var(--accent-muted);
        margin-left: 40px;
        border-left: 3px solid var(--accent);
      }

      .transcript-item.assistant {
        background: var(--bg-tertiary);
        margin-right: 40px;
        border-left: 3px solid var(--text-muted);
      }

      .transcript-item .role {
        font-size: 11px;
        text-transform: uppercase;
        letter-spacing: 1px;
        color: var(--text-muted);
        margin-bottom: 8px;
        font-weight: 600;
      }

      .transcript-item.user .role {
        color: var(--accent);
      }

      .transcript-item .content {
        color: var(--text-secondary);
      }

      .transcript-item.user .content {
        color: var(--text-primary);
      }

      /* Voice panel */
      .voice-panel {
        width: 35%;
        height: 100%;
        display: flex;
        flex-direction: column;
        align-items: center;
        justify-content: center;
        gap: 48px;
        padding: 40px;
        background: var(--bg-secondary);
      }

      .voice-title {
        text-align: center;
      }

      .voice-title h1 {
        font-size: 24px;
        font-weight: 600;
        color: var(--text-primary);
        margin-bottom: 8px;
      }

      .voice-title p {
        font-size: 14px;
        color: var(--text-secondary);
      }

      .circle-container {
        position: relative;
        width: 200px;
        height: 200px;
      }

      .voice-circle {
        width: 200px;
        height: 200px;
        border-radius: 50%;
        background: linear-gradient(135deg, var(--accent) 0%, #c44d24 100%);
        cursor: pointer;
        transition: all 0.3s ease;
        display: flex;
        align-items: center;
        justify-content: center;
        box-shadow:
          0 10px 40px rgba(232, 92, 43, 0.3),
          inset 0 2px 10px rgba(255, 255, 255, 0.1);
        position: relative;
        border: none;
        outline: none;
      }

      .voice-circle:hover {
        transform: scale(1.05);
        box-shadow:
          0 15px 50px rgba(232, 92, 43, 0.4),
          inset 0 2px 10px rgba(255, 255, 255, 0.15);
      }

      .voice-circle.listening {
        animation: pulse-listening 2s ease-in-out infinite;
        background: linear-gradient(135deg, #ff6b3d 0%, var(--accent) 100%);
      }

      .voice-circle.speaking {
        animation: pulse-speaking 1.5s ease-in-out infinite;
        background: linear-gradient(135deg, #ff8055 0%, var(--accent) 100%);
      }

      .voice-circle.processing {
        animation: pulse-processing 1s ease-in-out infinite;
        background: linear-gradient(135deg, #c44d24 0%, #a33d1a 100%);
      }

      .voice-circle.delegating {
        animation: pulse-delegating 0.8s ease-in-out infinite;
        background: linear-gradient(135deg, #b84520 0%, #8a3015 100%);
      }

      .waveform-icon {
        width: 80px;
        height: 80px;
        display: flex;
        align-items: center;
        justify-content: center;
        gap: 6px;
      }

      .waveform-bar {
        width: 8px;
        background: rgba(255, 255, 255, 0.9);
        border-radius: 4px;
        transition: all 0.3s ease;
      }

      .waveform-bar:nth-child(1) {
        height: 30px;
      }
      .waveform-bar:nth-child(2) {
        height: 50px;
      }
      .waveform-bar:nth-child(3) {
        height: 40px;
      }
      .waveform-bar:nth-child(4) {
        height: 60px;
      }
      .waveform-bar:nth-child(5) {
        height: 35px;
      }

      .voice-circle.listening .waveform-bar,
      .voice-circle.speaking .waveform-bar,
      .voice-circle.processing .waveform-bar,
      .voice-circle.delegating .waveform-bar {
        animation: waveform-pulse 1.2s ease-in-out infinite;
      }

      .voice-circle.listening .waveform-bar:nth-child(1) {
        animation-delay: 0s;
      }
      .voice-circle.listening .waveform-bar:nth-child(2) {
        animation-delay: 0.1s;
      }
      .voice-circle.listening .waveform-bar:nth-child(3) {
        animation-delay: 0.2s;
      }
      .voice-circle.listening .waveform-bar:nth-child(4) {
        animation-delay: 0.3s;
      }
      .voice-circle.listening .waveform-bar:nth-child(5) {
        animation-delay: 0.4s;
      }

      .voice-circle.speaking .waveform-bar:nth-child(1) {
        animation-delay: 0.4s;
      }
      .voice-circle.speaking .waveform-bar:nth-child(2) {
        animation-delay: 0.3s;
      }
      .voice-circle.speaking .waveform-bar:nth-child(3) {
        animation-delay: 0.2s;
      }
      .voice-circle.speaking .waveform-bar:nth-child(4) {
        animation-delay: 0.1s;
      }
      .voice-circle.speaking .waveform-bar:nth-child(5) {
        animation-delay: 0s;
      }

      @keyframes waveform-pulse {
        0%,
        100% {
          transform: scaleY(0.6);
          opacity: 0.7;
        }
        50% {
          transform: scaleY(1.2);
          opacity: 1;
        }
      }

      @keyframes pulse-listening {
        0%,
        100% {
          box-shadow:
            0 10px 40px rgba(232, 92, 43, 0.3),
            0 0 30px rgba(255, 107, 61, 0.2),
            inset 0 2px 10px rgba(255, 255, 255, 0.1);
          transform: scale(1);
        }
        50% {
          box-shadow:
            0 10px 60px rgba(232, 92, 43, 0.45),
            0 0 60px rgba(255, 107, 61, 0.35),
            inset 0 2px 15px rgba(255, 255, 255, 0.15);
          transform: scale(1.05);
        }
      }

      @keyframes pulse-speaking {
        0%,
        100% {
          box-shadow:
            0 10px 40px rgba(255, 128, 85, 0.35),
            0 0 35px rgba(255, 128, 85, 0.3),
            inset 0 2px 10px rgba(255, 255, 255, 0.1);
          transform: scale(1);
        }
        50% {
          box-shadow:
            0 10px 60px rgba(255, 128, 85, 0.5),
            0 0 70px rgba(255, 128, 85, 0.45),
            inset 0 2px 15px rgba(255, 255, 255, 0.15);
          transform: scale(1.08);
        }
      }

      @keyframes pulse-processing {
        0%,
        100% {
          box-shadow:
            0 10px 40px rgba(196, 77, 36, 0.3),
            0 0 25px rgba(196, 77, 36, 0.25),
            inset 0 2px 10px rgba(255, 255, 255, 0.1);
          transform: scale(1);
        }
        50% {
          box-shadow:
            0 10px 60px rgba(196, 77, 36, 0.4),
            0 0 50px rgba(196, 77, 36, 0.35),
            inset 0 2px 15px rgba(255, 255, 255, 0.15);
          transform: scale(1.03);
        }
      }

      @keyframes pulse-delegating {
        0%,
        100% {
          box-shadow:
            0 10px 40px rgba(184, 69, 32, 0.35),
            0 0 30px rgba(184, 69, 32, 0.3),
            inset 0 2px 10px rgba(255, 255, 255, 0.1);
          transform: scale(1);
        }
        50% {
          box-shadow:
            0 10px 60px rgba(184, 69, 32, 0.5),
            0 0 60px rgba(184, 69, 32, 0.45),
            inset 0 2px 15px rgba(255, 255, 255, 0.15);
          transform: scale(1.06);
        }
      }

      .audio-wave {
        position: absolute;
        top: 50%;
        left: 50%;
        transform: translate(-50%, -50%);
        width: 240px;
        height: 240px;
        border-radius: 50%;
        border: 2px solid rgba(232, 92, 43, 0.3);
        opacity: 0;
        animation: wave-expand 2s ease-out infinite;
        pointer-events: none;
      }

      .audio-wave:nth-child(2) {
        animation-delay: 0.5s;
      }
      .audio-wave:nth-child(3) {
        animation-delay: 1s;
      }

      .voice-circle.listening ~ .audio-wave,
      .voice-circle.speaking ~ .audio-wave {
        opacity: 1;
      }

      @keyframes wave-expand {
        0% {
          width: 200px;
          height: 200px;
          opacity: 0.8;
        }
        100% {
          width: 300px;
          height: 300px;
          opacity: 0;
        }
      }

      .status-text {
        font-size: 16px;
        color: var(--text-secondary);
        text-align: center;
        min-height: 24px;
        transition: all 0.3s ease;
        font-weight: 500;
      }

      .status-text.active {
        color: var(--accent);
      }

      .controls {
        display: flex;
        gap: 16px;
      }

      .control-button {
        padding: 12px 32px;
        background: transparent;
        border: 1px solid var(--border-color);
        border-radius: 8px;
        color: var(--text-secondary);
        font-size: 14px;
        cursor: pointer;
        transition: all 0.2s ease;
        font-weight: 500;
      }

      .control-button:hover {
        background: var(--bg-tertiary);
        border-color: var(--text-muted);
        color: var(--text-primary);
      }

      .control-button.danger {
        border-color: rgba(239, 68, 68, 0.3);
        color: var(--error);
      }

      .control-button.danger:hover {
        background: rgba(239, 68, 68, 0.1);
        border-color: var(--error);
      }

      /* Connection status */
      .connection-status {
        position: fixed;
        top: 16px;
        right: 32px;
        padding: 6px 12px;
        border-radius: 6px;
        font-size: 12px;
        font-weight: 500;
        background: var(--bg-tertiary);
        border: 1px solid var(--border-color);
      }

      .connection-status.connected {
        border-color: rgba(34, 197, 94, 0.3);
        color: var(--success);
      }

      .connection-status.disconnected {
        border-color: rgba(239, 68, 68, 0.3);
        color: var(--error);
      }

      /* Footer */
      .footer {
        padding: 16px 32px;
        text-align: center;
        font-size: 13px;
        color: var(--text-muted);
        background: var(--bg-primary);
        border-top: 1px solid var(--border-color);
      }

      .footer a {
        color: var(--accent);
        text-decoration: none;
        font-weight: 500;
      }

      .footer a:hover {
        color: var(--accent-hover);
        text-decoration: underline;
      }

      /* Placeholder text */
      .placeholder-text {
        color: var(--text-muted);
        font-size: 14px;
        text-align: center;
        padding: 40px 20px;
      }

      /* Text input */
      .input-form {
        display: flex;
        gap: 12px;
        margin-top: 16px;
        padding-top: 16px;
        border-top: 1px solid var(--border-color);
      }

      .text-input {
        flex: 1;
        padding: 12px 16px;
        background: var(--bg-secondary);
        border: 1px solid var(--border-color);
        border-radius: 8px;
        color: var(--text-primary);
        font-size: 14px;
        font-family: inherit;
        outline: none;
        transition: border-color 0.2s ease;
      }

      .text-input:focus {
        border-color: var(--accent);
      }

      .text-input::placeholder {
        color: var(--text-muted);
      }

      .text-input:disabled {
        opacity: 0.5;
        cursor: not-allowed;
      }

      .send-button {
        padding: 12px 20px;
        background: var(--accent);
        border: none;
        border-radius: 8px;
        color: white;
        font-size: 14px;
        font-weight: 500;
        cursor: pointer;
        transition: background 0.2s ease;
        display: flex;
        align-items: center;
        gap: 8px;
      }

      .send-button:hover:not(:disabled) {
        background: var(--accent-hover);
      }

      .send-button:disabled {
        opacity: 0.5;
        cursor: not-allowed;
      }

      .send-button svg {
        width: 16px;
        height: 16px;
      }

      /* Responsive */
      @media (max-width: 900px) {
        .container {
          flex-direction: column-reverse;
        }

        .transcript-panel,
        .voice-panel {
          width: 100%;
          height: auto;
        }

        .voice-panel {
          padding: 32px;
          gap: 32px;
          border-right: none;
          border-bottom: 1px solid var(--border-color);
        }

        .transcript-panel {
          flex: 1;
          min-height: 300px;
        }

        .circle-container {
          width: 160px;
          height: 160px;
        }

        .voice-circle {
          width: 160px;
          height: 160px;
        }

        .waveform-icon {
          width: 60px;
          height: 60px;
          gap: 4px;
        }

        .waveform-bar {
          width: 6px;
        }

        .waveform-bar:nth-child(1) {
          height: 24px;
        }
        .waveform-bar:nth-child(2) {
          height: 40px;
        }
        .waveform-bar:nth-child(3) {
          height: 32px;
        }
        .waveform-bar:nth-child(4) {
          height: 48px;
        }
        .waveform-bar:nth-child(5) {
          height: 28px;
        }

        @keyframes wave-expand {
          0% {
            width: 160px;
            height: 160px;
            opacity: 0.8;
          }
          100% {
            width: 240px;
            height: 240px;
            opacity: 0;
          }
        }

        .audio-wave {
          width: 200px;
          height: 200px;
        }
      }
    </style>
  </head>
  <body>
    <header class="header">
      <a href="https://autonomy.computer" target="_blank" rel="noopener">
        <svg class="logo" viewBox="0 0 652.94 59.4" xmlns="http://www.w3.org/2000/svg" aria-label="Autonomy">
          <path
            fill="currentColor"
            d="M79.05,0H29.25c-5.1,0-10.5,4.05-12.3,9.15L0,59.4h27.75l6.3-18.45h12.45l-3.15,9.3c-1.8,5.1.9,9.15,6,9.15h18.6l17.1-50.25c1.65-5.1-1.05-9.15-6-9.15ZM56.4,11.7l-7.35,21.6h-12.45l7.35-21.6c.75-2.4,3.6-4.5,6-4.5h3.45c2.4,0,3.75,2.1,3,4.5Z"
          />
          <path
            fill="currentColor"
            d="M122.7,47.7c-.9,2.55-3.6,4.5-6.15,4.5h-3.3c-2.55,0-3.9-1.95-3-4.5L126.3,0h-27.75l-16.95,50.25c-1.8,5.1.9,9.15,6,9.15h49.8c4.95,0,10.5-4.05,12.15-9.15L166.5,0h-27.75l-16.05,47.7Z"
          />
          <polygon
            fill="currentColor"
            points="234.45 0 171.3 0 168.75 7.2 186.6 7.2 168.9 59.4 196.65 59.4 214.35 7.2 232.05 7.2 234.45 0"
          />
          <path
            fill="currentColor"
            d="M298.04,0h-49.8c-5.1,0-10.5,4.05-12.3,9.15l-13.8,41.1c-1.8,5.1.9,9.15,6,9.15h49.8c4.95,0,10.5-4.05,12.15-9.15l13.95-41.1c1.65-5.1-1.05-9.15-6-9.15ZM275.39,11.7l-12.15,36c-.9,2.55-3.6,4.5-6.15,4.5h-3.3c-2.55,0-3.9-1.95-3-4.5l12.15-36c.75-2.4,3.6-4.5,6-4.5h3.45c2.4,0,3.75,2.1,3,4.5Z"
          />
          <path
            fill="currentColor"
            d="M376.49,0h-58.95l-20.1,59.4h27.75l17.7-52.2h7.95c2.55,0,3.75,1.95,3,4.5l-16.2,47.7h27.75l17.1-50.25c1.65-5.1-1.05-9.15-6-9.15Z"
          />
          <path
            fill="currentColor"
            d="M454.94,0h-49.8c-5.1,0-10.5,4.05-12.3,9.15l-13.8,41.1c-1.8,5.1.9,9.15,6,9.15h49.8c4.95,0,10.5-4.05,12.15-9.15l13.95-41.1c1.65-5.1-1.05-9.15-6-9.15ZM432.29,11.7l-12.15,36c-.9,2.55-3.6,4.5-6.15,4.5h-3.3c-2.55,0-3.9-1.95-3-4.5l12.15-36c.75-2.4,3.6-4.5,6-4.5h3.45c2.4,0,3.75,2.1,3,4.5Z"
          />
          <path
            fill="currentColor"
            d="M565.49,0h-91.05l-20.1,59.4h26.4l17.55-52.2h6c2.55,0,3.9,1.95,3,4.5l-16.05,47.7h26.4l17.55-52.2h6c2.55,0,3.9,1.95,3,4.5l-16.05,47.7h26.25l17.1-50.25c1.65-5.1-1.05-9.15-6-9.15Z"
          />
          <path
            fill="currentColor"
            d="M625.19,0l-10.35,30.6c-.9,2.55-3.6,4.65-6.15,4.65h-3.3c-2.55,0-3.9-2.1-3-4.65l10.35-30.6h-27.75l-12.45,36.9c-1.05,3,.6,5.55,3.6,5.55h34.8l-1.8,5.25c-.9,2.55-3.6,4.5-6.15,4.5h-32.55l-2.55,7.2h55.95c4.95,0,10.5-4.05,12.15-9.15L652.94,0h-27.75Z"
          />
        </svg>
      </a>
    </header>

    <div id="connectionStatus" class="connection-status disconnected">Disconnected</div>

    <div class="container">
      <div class="transcript-panel">
        <div class="transcript-header">
          <h2>Conversation</h2>
        </div>
        <div id="transcriptContainer" class="transcript-container">
          <div class="transcript-item assistant">
            <div class="role">Assistant</div>
            <div class="content">
              Hey! I am your interface to a team of agents that were just created, just for you, on Autonomy Computer.
              This is a live demo. We have access to dozens of pages of documentation and general information about
              Autonomy! We are part of a multi-tenant application to demonstrate that every user gets a sandboxed set of
              agents - each with its own unique identity, state, memory, and tools.
            </div>
          </div>
        </div>
        <form id="inputForm" class="input-form">
          <input type="text" id="textInput" class="text-input" placeholder="Type your question..." autocomplete="off" />
          <button type="submit" id="sendButton" class="send-button">
            <svg
              xmlns="http://www.w3.org/2000/svg"
              viewBox="0 0 24 24"
              fill="none"
              stroke="currentColor"
              stroke-width="2"
              stroke-linecap="round"
              stroke-linejoin="round"
            >
              <line x1="22" y1="2" x2="11" y2="13"></line>
              <polygon points="22 2 15 22 11 13 2 9 22 2"></polygon>
            </svg>
            Send
          </button>
        </form>
      </div>

      <div class="voice-panel">
        <div class="voice-title">
          <p>Click to start a voice conversation about Autonomy</p>
        </div>

        <div class="circle-container">
          <button id="voiceCircle" class="voice-circle">
            <div class="waveform-icon">
              <div class="waveform-bar"></div>
              <div class="waveform-bar"></div>
              <div class="waveform-bar"></div>
              <div class="waveform-bar"></div>
              <div class="waveform-bar"></div>
            </div>
          </button>
          <div class="audio-wave"></div>
          <div class="audio-wave"></div>
          <div class="audio-wave"></div>
        </div>

        <div id="status" class="status-text">Click to start</div>

        <div class="controls">
          <button id="endButton" class="control-button danger" style="display: none">End Session</button>
        </div>
      </div>
    </div>

    <footer class="footer">
      Built with <a href="https://autonomy.computer/" target="_blank" rel="noopener">Autonomy</a>
    </footer>

    <script>
      const id = () => Math.random().toString(36).slice(2);
      const visitorId = id();

      // State
      let ws = null;
      let mediaStream = null;
      let audioContext = null;
      let workletNode = null;
      let isRecording = false;
      let isConnected = false;

      // Audio playback
      let playbackAudioContext = null;
      let nextPlayTime = 0;
      let scheduledSources = [];
      let isSpeaking = false;
      let lastAudioPlayTime = 0; // Track when audio started for echo cancellation grace period

      // DOM elements
      const voiceCircle = document.getElementById("voiceCircle");
      const status = document.getElementById("status");
      const endButton = document.getElementById("endButton");
      const connectionStatus = document.getElementById("connectionStatus");
      const transcriptContainer = document.getElementById("transcriptContainer");
      const inputForm = document.getElementById("inputForm");
      const textInput = document.getElementById("textInput");
      const sendButton = document.getElementById("sendButton");

      // Text chat state
      let isTextLoading = false;
      let conversationId = id();

      // Connect to WebSocket
      async function connect() {
        const protocol = window.location.protocol === "https:" ? "wss:" : "ws:";
        const wsUrl = `${protocol}//${window.location.host}/agents/docs/voice?scope=${visitorId}&conversation=${conversationId}`;

        return new Promise((resolve, reject) => {
          ws = new WebSocket(wsUrl);

          ws.onopen = () => {
            console.log("ðŸ”Œ WebSocket connected");
            isConnected = true;
            connectionStatus.textContent = "Connected";
            connectionStatus.className = "connection-status connected";
            ws.send(JSON.stringify({ type: "config" }));
            resolve();
          };

          ws.onmessage = async (event) => {
            const data = JSON.parse(event.data);
            await handleServerMessage(data);
          };

          ws.onclose = () => {
            console.log("ðŸ“ª WebSocket closed");
            isConnected = false;
            connectionStatus.textContent = "Disconnected";
            connectionStatus.className = "connection-status disconnected";
          };

          ws.onerror = (error) => {
            console.error("âŒ WebSocket error:", error);
            reject(error);
          };
        });
      }

      // Handle messages from server
      async function handleServerMessage(data) {
        const eventType = data.type;

        switch (eventType) {
          case "connected":
            console.log("âœ… Server confirmed:", data.message);
            if (data.config) {
              console.log("   Config:", data.config);
            }
            break;

          case "audio":
            isSpeaking = true;
            await playAudioChunk(data.audio);
            setCircleState("speaking");
            updateStatus("Speaking...");
            break;

          case "transcript":
            if (data.role === "user") {
              console.log("ðŸ—£ï¸ User:", data.text);
              addTranscript("user", data.text);
            } else {
              console.log("ðŸ¤– Autonomy:", data.text);
              addTranscript("assistant", data.text);
            }
            break;

          case "transcript_delta":
            break;

          case "speech_started":
            console.log("ðŸŽ¤ Speech started (interrupted=" + data.interrupted + ")");
            // Always clear audio queue when user starts speaking
            if (scheduledSources.length > 0) {
              console.log("ðŸ”‡ Clearing audio queue - user started speaking");
              clearAudioQueue();
            }
            isSpeaking = false;
            setCircleState("listening");
            updateStatus("Listening...");
            break;

          case "speech_stopped":
            console.log("â¸ï¸ Speech stopped");
            setCircleState("processing");
            updateStatus("Thinking...");
            break;

          case "response_complete":
            console.log("âœ… Response complete");
            isSpeaking = false;
            setCircleState("listening");
            updateStatus("Listening...");
            break;

          case "error":
            // Ignore "no active response" errors - these are normal when cancelling
            if (data.error && !data.error.includes("no active response")) {
              console.error("âŒ Server error:", data.error);
              updateStatus("Error: " + data.error);
            }
            break;
        }
      }

      // Start recording
      async function startRecording() {
        if (!isConnected) {
          updateStatus("Reconnecting...");
          await connect();
          await new Promise((resolve) => setTimeout(resolve, 500));
          if (!isConnected) {
            updateStatus("Failed to connect. Please try again.");
            return;
          }
        }

        if (isRecording) {
          stopRecording();
          return;
        }

        try {
          mediaStream = await navigator.mediaDevices.getUserMedia({
            audio: {
              channelCount: 1,
              sampleRate: 24000,
              echoCancellation: true,
              noiseSuppression: true,
              autoGainControl: true,
            },
          });

          audioContext = new (window.AudioContext || window.webkitAudioContext)({
            sampleRate: 24000,
          });

          // Create AudioWorklet for processing
          const workletCode = `
            class PCMProcessor extends AudioWorkletProcessor {
              constructor() {
                super();
                this.bufferSize = 4096;
                this.buffer = new Float32Array(this.bufferSize);
                this.bufferIndex = 0;
              }

              process(inputs, outputs, parameters) {
                const input = inputs[0];
                if (input && input[0]) {
                  const inputData = input[0];
                  for (let i = 0; i < inputData.length; i++) {
                    this.buffer[this.bufferIndex++] = inputData[i];
                    if (this.bufferIndex >= this.bufferSize) {
                      const pcm16 = new Int16Array(this.bufferSize);
                      let maxLevel = 0;
                      for (let j = 0; j < this.bufferSize; j++) {
                        const s = Math.max(-1, Math.min(1, this.buffer[j]));
                        pcm16[j] = s < 0 ? s * 0x8000 : s * 0x7FFF;
                        const absVal = Math.abs(this.buffer[j]);
                        if (absVal > maxLevel) maxLevel = absVal;
                      }
                      this.port.postMessage({ pcm16: pcm16.buffer, maxLevel }, [pcm16.buffer]);
                      this.buffer = new Float32Array(this.bufferSize);
                      this.bufferIndex = 0;
                    }
                  }
                }
                return true;
              }
            }
            registerProcessor('pcm-processor', PCMProcessor);
          `;

          const blob = new Blob([workletCode], { type: "application/javascript" });
          const workletUrl = URL.createObjectURL(blob);

          try {
            await audioContext.audioWorklet.addModule(workletUrl);
          } finally {
            URL.revokeObjectURL(workletUrl);
          }

          const source = audioContext.createMediaStreamSource(mediaStream);
          workletNode = new AudioWorkletNode(audioContext, "pcm-processor");

          workletNode.port.onmessage = (e) => {
            if (!isRecording || !ws || ws.readyState !== WebSocket.OPEN) return;

            const { pcm16, maxLevel } = e.data;

            // Client-side interruption detection - threshold 0.25 to avoid false positives from ambient noise
            // Also add 1000ms grace period after audio starts to avoid echo cancellation false positives
            const timeSinceAudioStart = Date.now() - lastAudioPlayTime;
            if (isSpeaking && scheduledSources.length > 0 && maxLevel > 0.25 && timeSinceAudioStart > 1000) {
              console.log("âš¡ Client-side interruption detected (level:", maxLevel.toFixed(3), ")");
              clearAudioQueue();
              isSpeaking = false;
              setCircleState("listening");
              updateStatus("Listening...");
            }

            const audioBase64 = btoa(String.fromCharCode(...new Uint8Array(pcm16)));
            ws.send(JSON.stringify({ type: "audio", audio: audioBase64 }));
          };

          source.connect(workletNode);
          workletNode.connect(audioContext.destination);

          isRecording = true;
          setCircleState("listening");
          updateStatus("Listening...");
          endButton.style.display = "block";

          // Disable text input during voice session
          textInput.disabled = true;
          sendButton.disabled = true;

          console.log("ðŸŽ¤ Recording started");
        } catch (error) {
          console.error("âŒ Error starting recording:", error);
          updateStatus("Microphone access denied");
        }
      }

      // Stop recording
      function stopRecording() {
        if (!isRecording) return;

        console.log("â¹ï¸ Stopping recording");
        isRecording = false;

        // Re-enable text input
        textInput.disabled = false;
        sendButton.disabled = false;

        if (workletNode) {
          workletNode.disconnect();
          workletNode = null;
        }

        if (mediaStream) {
          mediaStream.getTracks().forEach((track) => track.stop());
          mediaStream = null;
        }

        if (audioContext) {
          audioContext.close();
          audioContext = null;
        }

        setCircleState("");
        updateStatus("Stopped");
        endButton.style.display = "none";

        if (ws && ws.readyState === WebSocket.OPEN) {
          ws.send(JSON.stringify({ type: "close" }));
        }
      }

      // Clear audio queue
      function clearAudioQueue() {
        if (scheduledSources.length === 0) return;

        console.log("ðŸ”‡ Clearing audio queue (" + scheduledSources.length + " sources)");

        scheduledSources.forEach((source) => {
          try {
            source.stop();
          } catch (e) {}
        });
        scheduledSources = [];

        if (playbackAudioContext) {
          nextPlayTime = playbackAudioContext.currentTime;
        }
      }

      // Play audio chunk
      async function playAudioChunk(base64Audio) {
        try {
          if (!playbackAudioContext) {
            playbackAudioContext = new (window.AudioContext || window.webkitAudioContext)({
              sampleRate: 24000,
            });
            // Add a small buffer (50ms) to prevent underruns
            nextPlayTime = playbackAudioContext.currentTime + 0.05;
          }

          // Track when audio playback starts for echo cancellation grace period
          if (scheduledSources.length === 0) {
            lastAudioPlayTime = Date.now();
          }

          const audioBytes = Uint8Array.from(atob(base64Audio), (c) => c.charCodeAt(0));
          const pcm16 = new Int16Array(audioBytes.buffer);
          const float32 = new Float32Array(pcm16.length);

          for (let i = 0; i < pcm16.length; i++) {
            float32[i] = pcm16[i] / 32768.0;
          }

          const audioBuffer = playbackAudioContext.createBuffer(1, float32.length, 24000);
          audioBuffer.getChannelData(0).set(float32);

          const source = playbackAudioContext.createBufferSource();
          source.buffer = audioBuffer;
          source.connect(playbackAudioContext.destination);

          source.onended = () => {
            scheduledSources = scheduledSources.filter((s) => s !== source);
          };
          scheduledSources.push(source);

          // If we've fallen behind, catch up with a small buffer to prevent glitches
          const currentTime = playbackAudioContext.currentTime;
          if (nextPlayTime < currentTime) {
            // Add 30ms buffer when catching up to prevent choppy audio
            nextPlayTime = currentTime + 0.03;
          }

          source.start(nextPlayTime);
          nextPlayTime += audioBuffer.duration;
        } catch (error) {
          console.error("âŒ Error playing audio:", error);
        }
      }

      // Set circle visual state
      function setCircleState(state) {
        voiceCircle.classList.remove("listening", "speaking", "processing", "delegating");
        if (state) {
          voiceCircle.classList.add(state);
        }
      }

      // Update status text
      function updateStatus(message) {
        status.textContent = message;
        status.className = "status-text" + (message.includes("...") ? " active" : "");
      }

      // Add transcript to UI
      function addTranscript(role, text) {
        const placeholder = transcriptContainer.querySelector(".placeholder-text");
        if (placeholder) {
          placeholder.remove();
        }

        const item = document.createElement("div");
        item.className = `transcript-item ${role}`;
        item.innerHTML = `
          <div class="role">${role === "user" ? "You" : "Assistant"}</div>
          <div class="content">${text}</div>
        `;
        transcriptContainer.appendChild(item);
        transcriptContainer.scrollTop = transcriptContainer.scrollHeight;
      }

      // End session
      function endSession() {
        stopRecording();
        clearAudioQueue();

        if (ws) {
          ws.close();
          ws = null;
        }

        isConnected = false;
        connectionStatus.textContent = "Disconnected";
        connectionStatus.className = "connection-status disconnected";
        updateStatus("Click to start");
      }

      // Handle text form submission
      async function handleTextSubmit(e) {
        e.preventDefault();

        const message = textInput.value.trim();
        if (!message || isTextLoading || isRecording) return;

        textInput.value = "";
        isTextLoading = true;
        textInput.disabled = true;
        sendButton.disabled = true;

        // Add user message to transcript
        addTranscript("user", message);

        // Add placeholder for assistant response with unique ID
        const responseId = `streamingResponse-${Date.now()}`;
        const placeholder = document.createElement("div");
        placeholder.className = "transcript-item assistant";
        placeholder.innerHTML = `
          <div class="role">Assistant</div>
          <div class="content" id="${responseId}">...</div>
        `;
        transcriptContainer.appendChild(placeholder);
        transcriptContainer.scrollTop = transcriptContainer.scrollHeight;

        // Get reference to the response element BEFORE the fetch
        const responseEl = document.getElementById(responseId);

        try {
          const response = await fetch(`/agents/docs?stream=true`, {
            method: "POST",
            headers: {
              "Content-Type": "application/json",
            },
            body: JSON.stringify({
              message: message,
              scope: visitorId,
              conversation: conversationId,
            }),
          });

          if (!response.ok) {
            throw new Error("Failed to get response");
          }

          if (response.body) {
            // Handle newline-delimited JSON streaming from Autonomy HTTP API
            const reader = response.body.getReader();
            const decoder = new TextDecoder();
            let pendingText = "";
            let displayedText = "";
            let streamDone = false;
            let buffer = "";

            // Typewriter loop - runs independently of stream reading
            const typewriterLoop = async () => {
              const baseDelay = 2; // Base delay in ms
              const minCharsPerTick = 1;
              const maxCharsPerTick = 5; // Max chars to display per tick when catching up

              while (!streamDone || pendingText.length > 0) {
                if (pendingText.length > 0) {
                  // Calculate how many chars to display this tick
                  // Display more chars per tick if we have a backlog
                  const backlog = pendingText.length;
                  const charsToDisplay = Math.min(maxCharsPerTick, Math.max(minCharsPerTick, Math.floor(backlog / 10)));

                  const chars = pendingText.slice(0, charsToDisplay);
                  pendingText = pendingText.slice(charsToDisplay);
                  displayedText += chars;

                  responseEl.textContent = displayedText;
                  transcriptContainer.scrollTop = transcriptContainer.scrollHeight;

                  // Shorter delay when catching up
                  const delay = backlog > 50 ? 1 : baseDelay;
                  await new Promise((resolve) => setTimeout(resolve, delay));
                } else {
                  // No pending text, wait a bit before checking again
                  await new Promise((resolve) => setTimeout(resolve, 5));
                }
              }
            };

            // Start typewriter loop
            const typewriterPromise = typewriterLoop();

            // Helper to extract text from assistant message content
            function extractText(content) {
              if (typeof content === "string") {
                return content;
              } else if (content && typeof content === "object") {
                // Handle {type: "text", text: "..."} format
                if (content.type === "text" && content.text) {
                  return content.text;
                }
                // Handle {text: "..."} format
                if (content.text) {
                  return content.text;
                }
              } else if (Array.isArray(content)) {
                return content
                  .map((c) => extractText(c))
                  .filter(Boolean)
                  .join("");
              }
              return "";
            }

            // Helper to get assistant response from a parsed JSON object
            function getAssistantText(data) {
              // Format: {messages: [{role: "assistant", content: {...}}]}
              if (data.messages && Array.isArray(data.messages)) {
                for (let i = data.messages.length - 1; i >= 0; i--) {
                  const msg = data.messages[i];
                  if (msg.role === "assistant" && msg.content) {
                    return extractText(msg.content);
                  }
                }
              }
              // Format: {content: "..."} or {response: "..."}
              if (data.content) return extractText(data.content);
              if (data.response) return data.response;
              if (data.text) return data.text;
              return "";
            }

            while (true) {
              const { done, value } = await reader.read();
              if (done) break;

              buffer += decoder.decode(value, { stream: true });
              const lines = buffer.split("\n");
              buffer = lines.pop() || "";

              for (const line of lines) {
                if (!line.trim()) continue;
                try {
                  const data = JSON.parse(line);
                  console.log("ðŸ“¦ Parsed response chunk:", data);
                  const text = getAssistantText(data);
                  console.log("ðŸ“ Extracted text:", text);
                  if (text) {
                    // Queue text for typewriter effect
                    pendingText += text;
                  }
                } catch (parseErr) {
                  console.log("âš ï¸ Parse error for line:", line, parseErr);
                }
              }
            }

            // Process remaining buffer
            if (buffer.trim()) {
              console.log("ðŸ“¦ Processing remaining buffer:", buffer);
              try {
                const data = JSON.parse(buffer);
                console.log("ðŸ“¦ Parsed buffer:", data);
                const text = getAssistantText(data);
                console.log("ðŸ“ Extracted text from buffer:", text);
                if (text) {
                  // Queue text for typewriter effect
                  pendingText += text;
                }
              } catch (parseErr) {
                console.log("âš ï¸ Buffer parse error:", parseErr);
              }
            }

            // Signal stream is done and wait for typewriter to finish
            streamDone = true;
            await typewriterPromise;

            if (!displayedText) {
              responseEl.textContent = "No response received.";
            }
          } else {
            // Fallback for non-streaming
            const data = await response.json();
            responseEl.textContent = data.response || data.content || "No response";
          }
        } catch (error) {
          console.error("Text chat error:", error);
          responseEl.textContent = "Sorry, I encountered an error. Please try again.";
        } finally {
          isTextLoading = false;
          textInput.disabled = false;
          sendButton.disabled = false;
          textInput.focus();
        }
      }

      // Event listeners
      voiceCircle.addEventListener("click", startRecording);
      endButton.addEventListener("click", endSession);
      inputForm.addEventListener("submit", handleTextSubmit);

      // Handle Enter key in text input
      textInput.addEventListener("keydown", (e) => {
        if (e.key === "Enter" && !e.shiftKey) {
          e.preventDefault();
          inputForm.dispatchEvent(new Event("submit"));
        }
      });
    </script>
  </body>
</html>
