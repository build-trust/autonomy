---
title: 'Building a Custom Streaming API and UI'
mode: 'wide'
description: 'When building AI applications, providing real-time streaming responses creates a much better user experience than waiting for complete responses. This guide shows you how to build a minimal but effective streaming chat interface that displays responses character by character.'
---


# Building a Custom Streaming API and UI

When building AI applications, providing real-time streaming responses creates a much better user experience than waiting for complete responses. This guide shows you how to build a minimal but effective streaming chat interface that displays responses character by character.

## The Simple UI Approach That Works

The key to smooth streaming UI is surprisingly straightforward: **just append characters one by one with a small delay**. Don't overthink it with complex animation frameworks or typing libraries. This simple approach works reliably across all browsers and provides the satisfying typewriter effect users expect.

This approach can be adapted to any UI framework.

## Backend: Streaming API with Autonomy

Here's a minimal FastAPI server that streams AI responses:

```aaa/minimal-streaming-example/images/main/main.py#L1-44
from autonomy import Agent, HttpServer, Model, Node, NodeDep
from fastapi import FastAPI
from fastapi.responses import StreamingResponse
import json
from dataclasses import asdict, is_dataclass
from enum import Enum

def json_serializer(obj):
    if is_dataclass(obj):
        return asdict(obj)
    if isinstance(obj, Enum):
        return obj.value
    if hasattr(obj, '__dict__'):
        return obj.__dict__
    return str(obj)

app = FastAPI()
agent = None

@app.post("/chat")
async def chat(request: dict, node: NodeDep):
    global agent

    # Initialize agent once and reuse
    if not agent:
        try:
            agent = await Agent.start(
                node=node,
                name="streaming-agent",
                instructions="You are a helpful assistant. Give clear, engaging responses.",
                model=Model("claude-sonnet-4-v1")
            )
        except Exception as e:
            if "AlreadyExists" not in str(e):
                raise e

    message = request.get("message", "")
    scope = request.get("scope", None)
    conversation = request.get("conversation", None)

    async def stream_response():
        try:
            async for response in agent.send_stream(message, scope, conversation, timeout=60):
                yield json.dumps(response.snippet, default=json_serializer) + "\n"
        except Exception as e:
            yield json.dumps({"type": "error", "message": str(e)}) + "\n"

    return StreamingResponse(stream_response(), media_type="application/json")

Node.start(http_server=HttpServer(app=app))
```

### Key Backend Concepts:

1. **Agent Reuse**: Initialize the agent once and reuse it for all requests to avoid setup overhead
2. **Streaming Response**: Use FastAPI's `StreamingResponse` with newline-delimited JSON
3. **Error Handling**: Gracefully handle exceptions and stream error messages
4. **Custom JSON Serializer**: Handle dataclasses and complex objects in the streaming response

## Frontend: Character-by-Character Streaming

The frontend implementation focuses on simplicity and reliability:

```aaa/minimal-streaming-example/images/main/index.html#L80-130
async function appendCharByChar(text, delay = 5) {
    for (const char of text) {
        out.textContent += char;
        await new Promise((resolve) => setTimeout(resolve, delay));
        chatArea.scrollTop = chatArea.scrollHeight;
    }
}

async function processLine(line) {
    if (line.trim()) {
        const parsed = JSON.parse(line);
        for (const message of parsed.messages) {
            if (message?.content?.text) {
                await appendCharByChar(message.content.text);
            }
        }
    }
}

async function send(message) {
    input.disabled = true;
    addMessage(message, true);
    out = createAssistantMessage();
    const response = await fetch("/chat", {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({ message }),
    });
    const decoder = new TextDecoder();
    let buffer = "";
    for await (const chunk of response.body) {
        buffer += decoder.decode(chunk, { stream: true });
        const lines = buffer.split("\n");
        buffer = lines.pop();
        if (!out.textContent) input.value = "";
        for (const line of lines) await processLine(line);
    }
    await processLine(buffer);
    input.disabled = false;
    input.focus();
}
```

### Why This UI Approach Works:

1. **Simple Character Loop**: The `appendCharByChar` function just iterates through each character with a 5ms delay
2. **Auto-Scroll**: Each character addition scrolls the chat to bottom for continuous visibility  
3. **Stream Processing**: Handles chunked data by buffering incomplete lines
4. **User Experience**: Disables input during response and clears it once streaming starts

## Complete HTML Structure

The complete interface includes clean styling and proper event handling:

```aaa/minimal-streaming-example/images/main/index.html#L1-79
<!doctype html>
<html>
    <head>
        <meta charset="UTF-8" />
        <title>Minimal Streaming Chat</title>
        <style>
            body {
                font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, sans-serif;
                max-width: 800px;
                margin: 0 auto;
                padding: 20px;
                background: #f5f5f5;
            }

            .container {
                background: white;
                border-radius: 12px;
                box-shadow: 0 2px 10px rgba(0, 0, 0, 0.1);
                overflow: hidden;
            }

            .chat-area {
                height: 400px;
                overflow-y: auto;
                padding: 20px;
                background: #fafafa;
            }

            .message {
                margin: 15px 0;
                padding: 12px 16px;
                border-radius: 18px;
                max-width: 80%;
                word-wrap: break-word;
            }

            .user-message {
                background: #007bff;
                color: white;
                margin-left: auto;
                text-align: right;
            }

            .assistant-message {
                background: white;
                border: 1px solid #e1e5e9;
                margin-right: auto;
            }

            .input-container {
                padding: 20px;
                background: white;
                border-top: 1px solid #e1e5e9;
                display: flex;
                gap: 12px;
            }

            #in {
                flex: 1;
                padding: 12px 16px;
                border: 2px solid #e1e5e9;
                border-radius: 24px;
                outline: none;
                font-size: 14px;
            }
        </style>
    </head>
    <body>
        <div class="container">
            <div class="header">
                <h1>Minimal Streaming Chat</h1>
                <p>Chat with an AI assistant using streaming responses</p>
            </div>
            <div id="chatArea" class="chat-area"></div>
            <div class="input-container">
                <input type="text" id="in" placeholder="Type your message here..." />
                <button id="sendButton">Send</button>
            </div>
        </div>
        <!-- JavaScript continues... -->
    </body>
</html>
```

## Key Takeaways

1. **Keep the UI Simple**: The character-by-character approach with `setTimeout` is simple, reliable, and provides great UX
2. **Handle Streaming Properly**: Buffer incomplete JSON lines and process complete ones immediately
3. **Agent Reuse**: Initialize expensive resources once and reuse them
4. **Error Handling**: Stream errors as JSON so the frontend can handle them gracefully
5. **User Experience**: Disable input during responses, auto-scroll, and maintain focus

This approach gives you a production-ready streaming chat interface that users will love. The simplicity is its strengthâ€”it works consistently across all browsers and provides the smooth typing effect that makes AI interactions feel natural and engaging. This approach can also be easily adapted to any UI framework.

